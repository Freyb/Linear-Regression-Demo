import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np

xs = [-0.853139394534702, -0.788694586320693, -0.8161372335054249, -0.9348590075687678, -0.9177207335935921,
      -0.9042819182991438, -0.8141648128577179, -0.7992340770450184, -0.7953656426754757, -0.8056361534995726,
      -0.7701333014972596, -0.6125718303274064, -0.7700998001103453, -0.6459025707111713, -0.6949099032078417,
      -0.6637913715308068, -0.5980988671499927, -0.5581469130650476, -0.49847651193404363, -0.5858052932785675,
      -0.4380377676446007, -0.5117122154600893, -0.5034701145283716, -0.4047789646589386, -0.457607902922221,
      -0.4865017657346097, -0.5201653238601607, -0.3631407359344271, -0.32398777808066287, -0.3544606594213942,
      -0.27271391766968334, -0.2781302176226804, -0.22194639219574205, -0.2211063560699532, -0.3240616758259295,
      -0.19580107124795165, -0.2147252756159161, -0.13911332606761884, -0.2552351718963627, -0.09296113851810836,
      -0.15796295749401748, -0.16854389143114823, -0.11208440569648062, -0.11182353123955449, -0.02854286243352125,
      -0.04676367349103655, -0.16244044716932043, -0.1182086237203943, 0.05268569448905394, 0.006194520465140657,
      0.09851010538172852, 0.033256347459910574, 0.05155299722184678, -0.008280615211850195, 0.11169135837199873,
      0.09251428182405855, 0.0880426711394503, 0.2172581379180707, 0.21946051415423765, 0.2145131786806454,
      0.14083119425329887, 0.24588690621727807, 0.18308185823098352, 0.28763569072350126, 0.35127326509611084,
      0.22602066035251195, 0.31739430799272406, 0.2543264705571468, 0.4165116446594247, 0.4303833288650116,
      0.38341334609423805, 0.4904651511954211, 0.48471190774703754, 0.37613853075276843, 0.41916733102624965,
      0.4655568311291306, 0.5212162112058558, 0.44984027030899737, 0.5531273010700117, 0.5329369454136565,
      0.6089163035243668, 0.48687878009671276, 0.6306870253719437, 0.5094303897042127, 0.5423790259642925,
      0.6813330610546562, 0.6991590514478161, 0.7083994488592547, 0.7110140992415886, 0.8051597520645718,
      0.8017280391762054, 0.8184245330641821, 0.8146242816161453, 0.712999758570324, 0.8769561333294763,
      0.7896201948837234, 0.8144010465839076, 0.7900626485334212, 0.8362826273461602, 0.8089544288455824]
ys = [8.684780724312494, 8.995214468304821, 8.53072331432888, 8.51641633017475, 8.763441417139306, 8.47888201719202,
      8.553183566931796, 8.746488481662873, 8.709514101015174, 8.804642356768154, 9.101161335709628, 9.04549680690992,
      8.909174294783579, 8.9494837214653, 8.787664536293438, 9.026004587142227, 8.83734101180538, 9.06745300052256,
      9.499073302503628, 9.242351944269968, 9.034666384002705, 9.124442570977621, 9.400753377158221, 9.406469158977886,
      9.527848649314935, 9.468573875946694, 9.49460421027937, 9.576765193530568, 9.263407528288036, 9.601562250775178,
      9.644763375305992, 9.646929443892496, 9.585862859945042, 9.53433122940355, 9.247799532382885, 9.429625414780405,
      9.581096543975972, 9.595816679917668, 9.875861259413215, 10.04766186405553, 9.607732777722664, 9.4622477435114,
      10.011411811328871, 9.939217613494243, 9.840590213707523, 9.722561038322773, 9.537675607149547, 9.903420521657534,
      10.1128831601511, 9.736006724370936, 10.311933481775574, 9.78957734706794, 10.365736749230273, 10.165795589137517,
      10.03842240952747, 9.954992421959377, 10.382337798474737, 10.153464003150097, 10.368638210339727,
      10.178934589246827, 10.307339010767894, 10.521838151136873, 10.576196795340893, 10.43267273066815,
      10.425308650620368, 10.401785461153445, 10.350630476522216, 10.443395752520585, 10.439974134057069,
      10.46261817320275, 10.740280827533851, 11.020576618697975, 10.957038164431681, 10.392159947353282,
      10.46496999549115, 10.909763483707335, 10.53124035785328, 10.888542346835987, 10.767537965836642,
      10.65088748345954, 10.756001601890086, 10.939919964543867, 11.158564890369396, 10.94820645644374,
      10.625497466635588, 11.22117197485771, 10.812611892684815, 10.863857922947256, 10.889201550849318,
      11.18392163584716, 11.51373561733465, 11.454866281366295, 11.402474437789376, 11.245906191332978,
      11.473251139461762, 11.355731396905323, 11.170026137510533, 11.247553253661184, 11.275435790107089,
      11.52640622008678]

learning_rate = .1
iterations = 30

a = tf.Variable(0, dtype=tf.float64, name="a")
b = tf.Variable(0, dtype=tf.float64, name="b")
x = tf.placeholder(dtype=tf.float64, name="x")
y = tf.placeholder(dtype=tf.float64, name="y")

y_pred = a * x + b

cost = tf.reduce_mean(tf.square(y_pred - y))

optimizer = tf.train.GradientDescentOptimizer(learning_rate)
train_op = optimizer.minimize(cost)

init_op = tf.global_variables_initializer()

cost_history = list()

with tf.Session() as session:
	session.run(init_op)
	
	plt.ion()
	plt.show()
	
	for i in range(iterations):
		print("Iteration", i+1)
		_, cost_value = session.run([train_op, cost], {x: xs, y: ys})
		cost_history.append(cost_value)

		# Visualize
		interval = np.arange(-1, 1, .05)
		interval_y_pred = session.run(y_pred, {x: interval})
		
		plt.clf()
		plt.subplots_adjust(hspace=0.3)
		plt.subplot(211)
		plt.plot(xs, ys, 'bo', interval, interval_y_pred, 'r-')
		plt.title('Labeled data and predictions')
		plt.axis([-1, 1, 0, 15])
		
		plt.subplot(212)
		plt.plot(cost_history)
		plt.title("Cost function over iterations")
		
		plt.draw()
		plt.pause(0.001)
		input("Press [enter] to continue.")
input("Done")